---
title: "Initial SJ markdown"
author: "WF"
date: "30 01 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The analysis below corresponds with the data uploaded yesterday (27.01.21) on kaggle.com. In this case we will not go beyond the basic EDA. I will mainly concentrate on the file containing information about competitions. 

# How these data look like?

Lets begin with the data and libraries import:

```{r import}
library(tidyverse)
library(e1071)
competitions = read.csv('all_comps_r.csv',sep=',',dec='.',stringsAsFactors = TRUE)
results = read.csv('all_results.csv',sep=',',dec='.')
names = read.csv('all_names.csv',sep=',',dec='.',stringsAsFactors = TRUE)

summary(competitions)
summary(results)
```
In fact in competitions dataset we have mostly integer variables. What is interesting only from this code is that

* the NA values are apparent - mostly in these cases, when 
  + the wind/gate factor was not taken into account (roughly 25% of competitions and 20% of jumps, mainly in COC/FC competitions)
  + the style was not counted (all training rounds, roughly 45% of total number of jumps)
  + parsing of PDF file was not successful (roughly 6% of competitions, mainly before 2012/13 and for COC/FC types)
* most competitions was held in Germany and in Norway.

# Some insight plots - competitions dataset

Lets see the most fashioned places and countries, grouped also by the type of competition
```{r barplots, echo=FALSE}
counts <- as.data.frame(table(competitions$place,competitions$gender))
counts_raw <- counts[aggregate(Freq ~ Var1,counts, sum)$Freq>50,]
counts <- filter(counts,counts$Var1 %in% counts_raw$Var1)
counts %>%
  mutate(Var1 = fct_reorder(Var1,Freq,sum)) %>%
  ggplot(aes(x=Var1, y=Freq, fill=Var2)) +
    geom_bar(stat="identity", alpha=.6, width=.4) +
    coord_flip() +
    scale_fill_discrete(name = "Gender") +
    xlab("") +
    theme_bw()

countries <- as.data.frame(table(competitions$country,competitions$gender))
countries_raw <- countries[aggregate(Freq ~ Var1,countries, sum)$Freq>50,]
countries <- filter(countries,countries$Var1 %in% countries_raw$Var1)
countries %>%
  mutate(Var1 = fct_reorder(Var1,Freq,sum)) %>%
  ggplot(aes(x=Var1, y=Freq, fill=Var2)) +
    geom_bar(stat="identity", alpha=.6, width=.4) +
    coord_flip() +
    scale_fill_discrete(name = "Gender") +
    xlab("") +
    theme_bw()

competitions['type_str'] = cut(competitions$type, breaks = c(-0.5,0.5,1.5,2.5,3.5,5.5), labels=c('WC', 'COC', 'GP','FC','Other')) 

types <- as.data.frame(table(competitions$place,competitions$type_str))
types_raw <- types[aggregate(Freq ~ Var1,types, sum)$Freq>100,]
types <- filter(types,types$Var1 %in% types_raw$Var1)
types %>%
  mutate(Var1 = fct_reorder(Var1,Freq,sum)) %>%
  ggplot(aes(x=Var1, y=Freq, fill=Var2)) +
    geom_bar(stat="identity", alpha=.6, width=.4) +
    scale_fill_discrete(name = "Type") +
    coord_flip() +
    xlab("") +
    theme_bw()
```

As we can see, various hills and cities have different "target" and its own specificity in terms of organizing ski jumping competitions. Let's see the sizes of different objects appearing in the dataset and the counts:

```{r size}
competitions['size'] = cut(competitions$hill_size_x, breaks = c(0,85,120,160,300), labels=c('small', 'normal', 'large','flying hill')) 
ggplot(subset(competitions, gender %in% c("Men", "Women"))) +
  geom_bar(aes(x = size, color=gender),fill="white", alpha = 0.6, position="dodge")
ggplot(competitions) +
  geom_bar(aes(x = size, color=type_str),fill="white", alpha = 0.6, position="dodge")
```

From these figures we can see that

* women compete mostly on the normal hills and men jump mainly on the large objects,
* women participate in substantially less number of competitions than men,
* most NAs come from COC competitions (season 2010/11 with different format of PDF files),
* the leagues with lower rank (COC, GP, FC) tend to organize competitions on smaller hills, what doesn't surprise.

## Some insight plots - results dataset

Now we will try to say something about the "main" dataset, which comprises the results of the competitions mentioned above. First thing is that (unfortunately) some competitions from the competitions dataset don't appear in the main dataset, exactly we have the number of not-processed PDFs:

```{r missing}
length(setdiff(competitions$id,results$id))
```
That is about 10% of "missing" comps, and this is the result of problems while parsing (mainly from the years before 2012). I still try to include this files into the dataset, but that won't be easy.
Now we can plot the basic facts about the key columns. First we plot the density of speed variable:
```{r speed}
ggplot(subset(results, speed > 60 & speed < 120)) +
  geom_density(aes(x = speed),fill="white", alpha = 0.6)
ggplot(subset(merge(results[,c('speed','id')],competitions,by='id'), speed > 60 & speed < 120)) +
  geom_area(aes(x = speed, color=size),fill="white", alpha = 0.6, stat='bin', position = position_dodge())
```

We notice that the in-run speed varies mostly between 80 and 95 kilometers per hour, but this (as we can see further) is determined by the hill size (HS) of a given object. We can derive a similar plot in terms of achieved distance.

```{r distances}
ggplot(subset(results, dist>0)) +
  geom_density(aes(x = dist),fill="white", alpha = 0.6)
ggplot(subset(merge(results[,c('dist','id')],competitions[,c('id','size')],by='id'), dist>0)) +
  geom_area(aes(x = dist, color=size),fill="white", alpha = 0.6, stat='bin', position = position_dodge())
ggplot(subset(merge(results[,c('dist','id')],competitions[,c('id','size')],by='id'), dist>0)) +
  geom_density(aes(x = dist, color=size),fill="white", alpha = 0.6)+labs(title='Normalized plots of conditional densities')
```

What can be unexpected is that the variance of achieved distance is slightly higher on normal hills than on the large ones. In this conditional case the distribution is quite similar to normal, but it should be noted that the skewness is present here and is negative on every type of hill:

```{r skewness}
large_hill_data = subset(merge(results[,c('dist','id')],competitions[,c('id','size')],by='id'), dist>0 & size=='large')
summary(large_hill_data$dist)
skewness(large_hill_data$dist)
```


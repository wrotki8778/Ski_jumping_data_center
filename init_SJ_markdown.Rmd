---
title: "Initial SJ markdown"
author: "WF"
date: "07 02 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

The analysis below corresponds with the data uploaded recently (08.03.21) on kaggle.com. In this case we will not go beyond the basic EDA. I will mainly concentrate on the file containing information about competitions. 

# How these data look like?

Lets begin with the data and libraries import:

```{r import}
library(tidyverse)
library(e1071)
competitions = read.csv('all_comps_r.csv',sep=',',dec='.',stringsAsFactors = TRUE)
results = read.csv('all_results.csv',sep=',',dec='.')
names = read.csv('all_names.csv',sep=',',dec='.',stringsAsFactors = TRUE)
stats  = read.csv('all_stats_r.csv',sep=',',dec='.',stringsAsFactors = TRUE)
```

# Some insight plots - competitions dataset

We begin with the summary of this dataset:
```{r summary_comp}
summary(competitions)
```

In fact in competitions dataset we have mostly integer variables. What is interesting only from this code is that

* the NA values are apparent - mostly in these cases, when parsing of PDF file was not successful (roughly 6% of competitions, mainly before 2012/13 and for COC/FC types)
* most competitions was held in Germany and in Norway
* the most popular type of the competition is World Cup (type 0) and Continental Cup (type 1)
* the most popular type of hill is normal (hill size between 85 and 109 meters) and large (hill size between 110 and 184 meters).

Lets see the most fashioned places and countries, grouped also by the type of competition
```{r barplots, echo=FALSE}
counts <- as.data.frame(table(competitions$place,competitions$gender))
counts_raw <- counts[aggregate(Freq ~ Var1,counts, sum)$Freq>50,]
counts <- filter(counts,counts$Var1 %in% counts_raw$Var1)
counts %>%
  mutate(Var1 = fct_reorder(Var1,Freq,sum)) %>%
  ggplot(aes(x=Var1, y=Freq, fill=Var2)) +
    geom_bar(stat="identity", alpha=.6, width=.4) +
    coord_flip() +
    scale_fill_discrete(name = "Gender") +
    xlab("") +
    theme_bw()

countries <- as.data.frame(table(competitions$country,competitions$gender))
countries_raw <- countries[aggregate(Freq ~ Var1,countries, sum)$Freq>50,]
countries <- filter(countries,countries$Var1 %in% countries_raw$Var1)
countries %>%
  mutate(Var1 = fct_reorder(Var1,Freq,sum)) %>%
  ggplot(aes(x=Var1, y=Freq, fill=Var2)) +
    geom_bar(stat="identity", alpha=.6, width=.4) +
    coord_flip() +
    scale_fill_discrete(name = "Gender") +
    xlab("") +
    theme_bw()

competitions['type_str'] = cut(competitions$type, breaks = c(-0.5,0.5,1.5,2.5,3.5,5.5), labels=c('WC', 'COC', 'GP','FC','Other')) 

types <- as.data.frame(table(competitions$place,competitions$type_str))
types_raw <- types[aggregate(Freq ~ Var1,types, sum)$Freq>100,]
types <- filter(types,types$Var1 %in% types_raw$Var1)
types %>%
  mutate(Var1 = fct_reorder(Var1,Freq,sum)) %>%
  ggplot(aes(x=Var1, y=Freq, fill=Var2)) +
    geom_bar(stat="identity", alpha=.6, width=.4) +
    scale_fill_discrete(name = "Type") +
    coord_flip() +
    xlab("") +
    theme_bw()
```

As we can see, various hills and cities have different "target" and its own specificity in terms of organizing ski jumping competitions. Let's see the sizes of different objects appearing in the dataset and the counts:

```{r size}
competitions['size'] = cut(competitions$hill_size_x, breaks = c(0,85,120,160,300), labels=c('small', 'normal', 'large','flying hill')) 
ggplot(subset(competitions, gender %in% c("Men", "Women"))) +
  geom_bar(aes(x = size, color=gender),fill="white", alpha = 0.6, position="dodge")
ggplot(competitions) +
  geom_bar(aes(x = size, color=type_str),fill="white", alpha = 0.6, position="dodge")
```

From these figures we can see that

* women compete mostly on the normal hills and men jump mainly on the large objects,
* women participate in substantially less number of competitions than men,
* most NAs come from COC competitions (season 2010/11 with different format of PDF files),
* the leagues with lower rank (COC, GP, FC) tend to organize competitions on smaller hills, what doesn't surprise.

# Some insight plots - stats dataset

We also obtained a dataset with the additional statistics, which contains weather information, but also the data like base start gate (gate variable) and name of the given round. First lets see the summary:

```{r summary_stats}
summary(stats)
```
The most apparent conclusions:

* statistically in each round we have 30-60 jumpers from 10-15 countries
* some data are absurd like 515% humidity or -87 Celsius degrees of snow temp. This is not the error in parsing - these are the "real" values from PDFs.
* almost all variables have some NAs - it follows from the errors while parsing.

Now we can plot some figures of single variables. We will accomplish that step by step.

```{r stats_plots}
stats['summer'] = apply(stats[,c('snow','air')], 1, function(y){
  if (is.na(y['snow'])==1 & is.na(y['air']) == 0) return('summer')
  else if (is.na(y['snow']) == 0 & is.na(y['air']) == 0) return('winter')
  return(NA)
  })
ggplot(stats) +
  geom_density(aes(x = air, color = summer),fill="white", alpha = 0.6)+labs(title='Temperature plot')
ggplot(stats) +
  geom_density(aes(x = humid, color = summer),fill="white", alpha = 0.6)+labs(title='Humidity plot')+xlim(0,100)
ggplot(stats) +
  geom_density(aes(x = snow),fill="white", alpha = 0.6)+labs(title='Snow temperature plot in winter')+xlim(-25,5)
```

We can see that the temperatures in winter varies around the zero value, in the summer it is about 20 degrees. We observe also the differences in humidity - in the winter months the percentage values are substantially higher than in the summer. Snow temperature has skewed distribution with the mode around -6 degrees. In the dataset we can obtain also the number of athletes. We will divide our results by gender and the type of competition.

```{r athletes_stats}
unique_stats = stats[!duplicated(stats$fis_code),]
tmp_data = merge(unique_stats,competitions,by.x = 'fis_code', by.y = 'id')
tmp_data['jumpers']= cut(tmp_data$all_jumpers, breaks = c(0,35,45,55,65,75,110)) 
ggplot(tmp_data) +
  geom_bar(aes(x = jumpers, color=gender),fill="white", alpha = 0.6, position="dodge")
ggplot(tmp_data) +
  geom_bar(aes(x = jumpers, color=type_str),fill="white", alpha = 0.6, position="dodge")
```

That is quite interesting because the distribution of participating jumpers is much more uniform or even convex, when we consider Continental Cup or especially FIS Cup instead of World Cup, where the values concentrate about 50 athletes. Much of this is the effect of the qualification rounds, when a priori we choose 40/50 (depends on the gender) best jumpers to further jumps.

# Some insight plots - results dataset

Now we will try to say something about the "main" dataset, which comprises the results of the competitions mentioned above. First thing is that (unfortunately) some competitions from the competitions dataset don't appear in the main dataset, exactly we have the number of not-processed PDFs:

```{r missing}
length(setdiff(competitions$id,results$id))
```
That is about 10% of "missing" comps, and this is the result of problems while parsing (mainly from the years before 2012). I still try to include this files into the dataset, but that won't be easy.
Now we can plot the basic facts about the key columns. First we write down the summary of our dataset:
```{r summary_results}
summary(results)
```

In fact we observe a lot of NAs, but mainly in the cases where the considered variable was not measured. For instance, variables with "note" appear only in the competition rounds, not in the training or trial rounds.

Next plot the density of speed variable:
```{r speed}
ggplot(subset(results, speed > 60 & speed < 120)) +
  geom_density(aes(x = speed),fill="white", alpha = 0.6)
ggplot(subset(merge(results[,c('speed','id')],competitions,by='id'), speed > 60 & speed < 120)) +
  geom_area(aes(x = speed, color=size),fill="white", alpha = 0.6, stat='bin', position = position_dodge())
```

We notice that the in-run speed varies mostly between 80 and 95 kilometers per hour, but this (as we can see further) is determined by the hill size (HS) of a given object. We can derive a similar plot in terms of achieved distance.

```{r distances}
ggplot(subset(results, dist>0)) +
  geom_density(aes(x = dist),fill="white", alpha = 0.6)
ggplot(subset(merge(results[,c('dist','id')],competitions[,c('id','size')],by='id'), dist>0)) +
  geom_area(aes(x = dist, color=size),fill="white", alpha = 0.6, stat='bin', position = position_dodge())
ggplot(subset(merge(results[,c('dist','id')],competitions[,c('id','size')],by='id'), dist>0)) +
  geom_density(aes(x = dist, color=size),fill="white", alpha = 0.6)+labs(title='Normalized plots of conditional densities')
```

What can be unexpected is that the variance of achieved distance is slightly higher on normal hills than on the large ones. In this conditional case the distribution is quite similar to normal, but it should be noted that the skewness is present here and is negative on every type of hill:

```{r skewness}
large_hill_data = subset(merge(results[,c('dist','id')],competitions[,c('id','size')],by='id'), dist>0 & size=='large')
summary(large_hill_data$dist)
skewness(large_hill_data$dist)
```

Next, we take a look on the additional variables like note_points and wind:

```{r style_1}
ggplot(results) +
  geom_density(aes(x = note_points),fill="white", alpha = 0.6)
```

We can see that this plot is weirdly ragged. This can be explained by the fact, that the judges tend to give the same score, so the values 51 (3 times 17.0), 52.5 (3 times 17.5) etc. are preferred. The conclusion is that it's more acceptable to take only one judge and see the distribution.

```{r style_2}
ggplot(results) +
  geom_histogram(aes(x = note_1, y=..density..), breaks=seq(0,20,by=0.5))
```

As an exercise we will estimate the distribution by the beta family of distributions. Next we visualize how well our distribution is approximated by this approach.

```{r style_beta}
library(EnvStats)

parameters=ebeta(results$note_1/20)
print(parameters)

ggplot(results) +
  geom_histogram(aes(x = note_1/20, y=..density..), breaks=seq(0,1,length.out = 41)) +
  stat_function(fun = dbeta, args = list(shape1 = parameters$parameters[1], shape2 = parameters$parameters[2]))
```

Although the goodness of fit is not perfect, the nature of this variable is quite evident. Next we will see what is going on with the wind variable:

```{r wind}
summary(results$wind)
ggplot(results) +
  geom_density(aes(x = wind),fill="white", alpha = 0.6)
```

This plot is somewhat surprising, because it should be intuitive that the distribution of winds should be symmetric, but it does not meet that property. However, if we draw a density of *wind_comp* variable, then it becomes symmetric.

```{r wind_points}
summary(results$wind_comp)
ggplot(results) +
  geom_density(aes(x = wind_comp),fill="white", alpha = 0.6)
```

The purpose of this result is that the wind compensations are adjusted -- the bonus from the tail wind is bigger than the penalty from the head wind. As we can see, this method works quite well.

## Conclusions

As we could see, even these aggregate way of using our data brings quite attractive plots. Of course, by taking both of these datasets together, we can do a lot more of statistical analysis. I am sure that these observations contain a massive amount of knowledge which is not discovered yet.

If time allows, I will upload some more advanced markdowns with more particular insights. I have a few questions which should be answered within a few weeks or months. Maybe someone else also has an idea how use this information. See you later!


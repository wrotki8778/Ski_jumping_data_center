sex,
relationship_status,
diet_score,
diet_score_h,
sport_score,
sport_score_h,
workout_score,
workout_score_h,
hobbies_score,
hobbies_score_h
)
)
return(X)
}
train_models <- function(data, print = TRUE){
X = filter_dataset(data)
y = data$target
reg = glm(
target ~ new_dob + sex + relationship_status + hobbies_score + hobbies_score_h + diet_score + diet_score_h + sport_score + sport_score_h + workout_score + workout_score_h,
data = data,
family = binomial()
)
mars1 <- earth(X, y,
degree = 2,
nprune = 20,
glm = list(family=binomial))
rf1 <- randomForest(X, as.factor(y), mtry = 3)
if(print){
print(summary(reg))
print(summary(mars1))
print(rf1)
}
return(list(reg,mars1,rf1))
}
predict_models <- function(data, models){
X = filter_dataset(data)
data['decision']=0
i=1
column_names = c()
for(model in models){
column_name = paste('fitted_',i, sep='')
column_name_2 = paste('decision_',i, sep='')
column_names = c(column_name,column_name)
print(column_name)
if(!is.null(model$type)){
print(predict(model,X,type='prob')[,2])
data[column_name] = predict(model,X,type='prob')[,2]
}
else data[column_name] = predict(model,X,type='response')
data[column_name_2] = ifelse(data[column_name]>1/2,1,0)
i=i+1
}
data['decision']=ifelse(rowSums(data[,column_names])>length(column_names)/2,1,0)
return(data)
}
train_csv = read.csv(
'new_train.csv',
stringsAsFactors = TRUE,
fileEncoding = 'UTF-8',
na.strings = ""
)
test_csv = read.csv(
'new_test.csv',
stringsAsFactors = TRUE,
fileEncoding = 'UTF-8',
na.strings = ""
)
train_csv['train'] = TRUE
test_csv['target'] = NA
test_csv['train'] = FALSE
all_data_csv = rbind(train_csv,test_csv)
ost_lit = apply(all_data_csv['name'], 1, gender)
all_data_csv = cbind(all_data_csv, ost_lit)
all_data_csv['sex'][is.na(all_data_csv['sex'])] = all_data_csv['ost_lit'][is.na(all_data_csv['sex'])]
all_data_csv['dob'] = as.Date.factor(all_data_csv['dob'][, 1])
all_data_csv['new_dob'] = as.numeric(Sys.Date()) - as.numeric(all_data_csv$dob)
all_data_csv['diet'] = as.factor(ifelse(all_data_csv['diet_score'] + all_data_csv['diet_score_h'] >
0, TRUE, FALSE))
all_data_csv['sport'] = as.factor(ifelse(all_data_csv['sport_score'] + all_data_csv['sport_score_h'] >
0, TRUE, FALSE))
all_data_csv['workout'] = as.factor(ifelse(all_data_csv['workout_score'] + all_data_csv['workout_score_h'] >
0, TRUE, FALSE))
all_data_csv['hobbies_'] = as.factor(ifelse(all_data_csv['hobbies_score'] + all_data_csv['hobbies_score_h'] >
0, TRUE, FALSE))
variables = c(
'sex',
'relationship_status',
'hobbies_',
'diet',
'sport',
'workout',
'new_dob'
)
impute_data = all_data_csv[, variables]
pdag = iamb(impute_data)
plot(pdag)
dag = pdag2dag(
pdag,
variables
)
plot(dag)
training_structure = bn.fit(dag, impute_data)
imputed_data = impute(training_structure, impute_data)
all_data_csv[, variables] = imputed_data
N = nrow(train_csv)
set.seed(1)
train_sample = sample(N,floor(0.75*N))-1
train_csv = all_data_csv[(all_data_csv$train == TRUE)  & (all_data_csv$user_id %in% train_sample), ]
validation_csv = all_data_csv[(all_data_csv$train == TRUE)  & (1 - all_data_csv$user_id %in% train_sample),]
test_csv = all_data_csv[all_data_csv$train == FALSE, ]
models = train_models(train_csv)
train_csv = predict_models(train_csv, models)
validation_csv = predict_models(validation_csv, models)
require(caret)
print("For linear regression:")
print(confusionMatrix(
as.factor(validation_csv$decision_1),
as.factor(validation_csv$target)
))
print("For MARS:")
print(confusionMatrix(
as.factor(validation_csv$decision_2),
as.factor(validation_csv$target)
))
print("For random forest:")
print(confusionMatrix(
as.factor(validation_csv$decision_3),
as.factor(validation_csv$target)
))
print("For combined output:")
print(confusionMatrix(
as.factor(validation_csv$decision),
as.factor(validation_csv$target)
))
final_train_csv = rbind(train_csv, validation_csv)
final_models = train_models(final_train_csv, print = FALSE)
test_csv = predict_models(test_csv, list(final_models[[1]]))
library(mgcv)
library(tidyverse)
library(glmnet)
library(earth)
library(caret)
library(randomForest)
library(bnlearn)
substrRight <- function(x, n) {
substr(x, nchar(x) - n + 1, nchar(x))
}
gender <- function(name) {
if (is.na(name))
return('male')
n = substrRight(name, 1)
if (n == 'a') {
return('female')
}
return('male')
}
filter_dataset <- function(data){
X = subset(
data,
select = c(
new_dob,
sex,
relationship_status,
diet_score,
diet_score_h,
sport_score,
sport_score_h,
workout_score,
workout_score_h,
hobbies_score,
hobbies_score_h
)
)
return(X)
}
train_models <- function(data, print = TRUE){
X = filter_dataset(data)
y = data$target
reg = glm(
target ~ new_dob + sex + relationship_status + hobbies_score + hobbies_score_h + diet_score + diet_score_h + sport_score + sport_score_h + workout_score + workout_score_h,
data = data,
family = binomial()
)
mars1 <- earth(X, y,
degree = 2,
nprune = 20,
glm = list(family=binomial))
rf1 <- randomForest(X, as.factor(y), mtry = 3)
if(print){
print(summary(reg))
print(summary(mars1))
print(rf1)
}
return(list(reg,mars1,rf1))
}
predict_models <- function(data, models){
X = filter_dataset(data)
data['decision']=0
i=1
column_names = c()
for(model in models){
column_name = paste('fitted_',i, sep='')
column_name_2 = paste('decision_',i, sep='')
column_names = c(column_name,column_name)
if(!is.null(model$type)){
data[column_name] = predict(model,X,type='prob')[,2]
}
else data[column_name] = predict(model,X,type='response')
data[column_name_2] = ifelse(data[column_name]>1/2,1,0)
i=i+1
}
data['decision']=ifelse(rowSums(data[,column_names])>length(column_names)/2,1,0)
return(data)
}
train_csv = read.csv(
'new_train.csv',
stringsAsFactors = TRUE,
fileEncoding = 'UTF-8',
na.strings = ""
)
test_csv = read.csv(
'new_test.csv',
stringsAsFactors = TRUE,
fileEncoding = 'UTF-8',
na.strings = ""
)
train_csv['train'] = TRUE
test_csv['target'] = NA
test_csv['train'] = FALSE
all_data_csv = rbind(train_csv,test_csv)
ost_lit = apply(all_data_csv['name'], 1, gender)
all_data_csv = cbind(all_data_csv, ost_lit)
all_data_csv['sex'][is.na(all_data_csv['sex'])] = all_data_csv['ost_lit'][is.na(all_data_csv['sex'])]
all_data_csv['dob'] = as.Date.factor(all_data_csv['dob'][, 1])
all_data_csv['new_dob'] = as.numeric(Sys.Date()) - as.numeric(all_data_csv$dob)
all_data_csv['diet'] = as.factor(ifelse(all_data_csv['diet_score'] + all_data_csv['diet_score_h'] >
0, TRUE, FALSE))
all_data_csv['sport'] = as.factor(ifelse(all_data_csv['sport_score'] + all_data_csv['sport_score_h'] >
0, TRUE, FALSE))
all_data_csv['workout'] = as.factor(ifelse(all_data_csv['workout_score'] + all_data_csv['workout_score_h'] >
0, TRUE, FALSE))
all_data_csv['hobbies_'] = as.factor(ifelse(all_data_csv['hobbies_score'] + all_data_csv['hobbies_score_h'] >
0, TRUE, FALSE))
variables = c(
'sex',
'relationship_status',
'hobbies_',
'diet',
'sport',
'workout',
'new_dob'
)
impute_data = all_data_csv[, variables]
pdag = iamb(impute_data)
plot(pdag)
dag = pdag2dag(
pdag,
variables
)
plot(dag)
training_structure = bn.fit(dag, impute_data)
imputed_data = impute(training_structure, impute_data)
all_data_csv[, variables] = imputed_data
N = nrow(train_csv)
set.seed(1)
train_sample = sample(N,floor(0.75*N))-1
train_csv = all_data_csv[(all_data_csv$train == TRUE)  & (all_data_csv$user_id %in% train_sample), ]
validation_csv = all_data_csv[(all_data_csv$train == TRUE)  & (1 - all_data_csv$user_id %in% train_sample),]
test_csv = all_data_csv[all_data_csv$train == FALSE, ]
models = train_models(train_csv)
train_csv = predict_models(train_csv, models)
validation_csv = predict_models(validation_csv, models)
require(caret)
print("For linear regression:")
print(confusionMatrix(
as.factor(validation_csv$decision_1),
as.factor(validation_csv$target)
))
print("For MARS:")
print(confusionMatrix(
as.factor(validation_csv$decision_2),
as.factor(validation_csv$target)
))
print("For random forest:")
print(confusionMatrix(
as.factor(validation_csv$decision_3),
as.factor(validation_csv$target)
))
print("For combined output:")
print(confusionMatrix(
as.factor(validation_csv$decision),
as.factor(validation_csv$target)
))
final_train_csv = rbind(train_csv, validation_csv)
final_models = train_models(final_train_csv, print = FALSE)
test_csv = predict_models(test_csv, list(final_models[[1]]))
View(validation_csv)
warnings()
knitr::opts_chunk$set(include=TRUE, message=FALSE, warning=FALSE)
knitr::opts_chunk$set(out.width="100%", fig.height = 4.5, split=FALSE, fig.align = 'default')
options(dplyr.summarise.inform = FALSE)
validation_csv = predict_models(validation_csv, models)
require(caret)
print("For linear regression:")
print(confusionMatrix(
as.factor(validation_csv$decision_1),
as.factor(validation_csv$target)
))
print("For MARS:")
print(confusionMatrix(
as.factor(validation_csv$decision_2),
as.factor(validation_csv$target)
))
print("For random forest:")
print(confusionMatrix(
as.factor(validation_csv$decision_3),
as.factor(validation_csv$target)
))
print("For combined output:")
print(confusionMatrix(
as.factor(validation_csv$decision),
as.factor(validation_csv$target)
))
binom.test(100, 20, p=0.5)
?binom.test
binom.test(20, 100, p=0.5)
binom.test(20, 100, p=0.5, alternative = c('less'))
binom.test(20, 100, p=0.5, alternative = c('greater'))
?prop.test
prop.test(c(20,100),c(100,500),correct=F)
prop.test(c(1,25),c(60,1500),correct=F)
prop.test(c(1,25),c(200,1500),correct=FALSE)
prop.test(c(1,25),c(200,1500),correct=TRUE)
prop.test(c(1,25),c(100,1500),correct=TRUE)
prop.test(c(1,25),c(1500,1500),correct=TRUE)
prop.test(c(1,25),c(1500,1500),correct=FALSE)
prop.test(c(1,25),c(200,1500),correct=FALSE)
prop.test(c(43,28),c(66,58),correct=FALSE)
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('less'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('greater'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('less'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('less'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('less'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('less'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('two.sided'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('two.sided'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('two.sided'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('less'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('less'))
prop.test(c(1,25),c(200,1500),correct=FALSE, alternative = c('two.sided'))
prop.test(c(1,25),c(1500,1500),correct=FALSE, alternative = c('two.sided'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('less'))
prop.test(c(1,25),c(1500,1500),correct=FALSE, alternative = c('greater'))
prop.test(c(1,25),c(200,1500),correct=FALSE, alternative = c('less'))
prop.test(c(1,25),c(200,1500),correct=FALSE, alternative = c('greater'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('less'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('greater'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('greater'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('two.sided'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('two.sided'))
prop.test(c(43,28),c(66,58),correct=TRUE, alternative=c('two.sided'))
prop.test(c(30,71),c(32,85),correct=TRUE, alternative=c('two.sided'))
prop.test(c(43,28),c(66,58),correct=TRUE, alternative=c('greater'))
prop.test(c(30,71),c(32,85),correct=TRUE, alternative=c('greater'))
prop.test(c(43,28),c(66,58),correct=FALSE, alternative=c('greater'))
prop.test(c(30,71),c(32,85),correct=FALSE, alternative=c('greater'))
setwd("~/GitHub/Ski_jumping_data_center")
setwd("~/GitHub/Ski_jumping_data_center")
competitions = read.csv('all_comps.csv',sep=',',dec='.',stringsAsFactors = TRUE)
View(competitions)
results = read.csv('all_results.csv',sep=',',dec='.',stringsAsFactors = TRUE)
ratings = read.csv('all_ratings.csv',sep=',',dec='.',stringsAsFactors = TRUE)
View(ratings)
competitions = read.csv('all_comps.csv',sep=',',dec='.',stringsAsFactors = TRUE)
results = read.csv('all_results.csv',sep=',',dec='.',stringsAsFactors = TRUE)
ratings = read.csv('all_ratings.csv',sep=',',dec='.',stringsAsFactors = TRUE)
our_data = merge(results,ratings, by=c('codex','id','round'))
View(our_data)
View(competitions)
library(dplyr)
library(lme4)
library(tidyverse)
library(lme4)
our_data = merge(results,ratings, by=c('codex','id','round')) %>% merge(competitions, by=c('codex','id'))
View(our_data)
View(competitions)
our_data = merge(results,ratings, by=c('codex','id','round')) %>% merge(competitions, by=c('id'))
View(our_data)
our_data = our_data %>% filter(c(codex,hill_size.x,dist,wind,speed,training))
View(our_data)
our_data = merge(results,ratings, by=c('codex.x','id','round')) %>% merge(competitions, by=c('id'))
our_data = our_data %>% filter(c(codex,hill_size.x,dist,wind,speed,training))
our_data = merge(results,ratings, by=c('codex','id','round')) %>% merge(competitions, by=c('id'))
our_data = our_data %>% filter(c(codex.x,hill_size.x,dist,wind,speed,training))
View(our_data)
our_data = our_data %>% filter(c(codex.x,hill_size_x,dist,wind,speed,training))
?filter
browseVignettes(package = "dplyr")
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training)
View(our_data)
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training) %>% drop_na
View(our_data)
our_data['hill_type'] = cut(our_data['hill_size_x'], breaks = c(0,85,120,160,300), labels=c('small', 'normal', 'large','flying hill'))
View(our_data)
our_data['hill_type'] = cut(our_data['hill_size_x'], breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
our_data['hill_type'] = cut(our_data$hill_size_x, breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
View(our_data)
our_data['codex.x'] = as.factor(our_data['codex.x'])
View(our_data)
our_data = merge(results,ratings, by=c('codex','id','round')) %>% merge(competitions, by=c('id'))
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training) %>% drop_na
our_data['hill_type'] = cut(our_data$hill_size_x, breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
our_data['codex.x'] = as.factor.numeric(our_data['codex.x'])
our_data['codex.x'] = as_factor.numeric(our_data['codex.x'])
?as_factor.numeric
View(our_data)
our_data['codex.factor'] = as.factor.numeric(our_data['codex.x'])
our_data['codex.factor'] = as_factor(our_data['codex.x'])
View(our_data)
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training) %>% drop_na
our_data['hill_type'] = cut(our_data$hill_size_x, breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
our_data['codex.factor'] = as_factor(our_data['codex.x'])
View(our_data)
summary(our_data)
our_data['codex.factor'] = factor(x=our_data$codex.x)
View(our_data)
summary(our_data)
our_data['hill_type'] = cut(our_data$hill_size_x, breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
our_data['norm_dist'] = our_data$dist/our_data$hill_size_x
our_data['codex.factor'] = factor(x=our_data$codex.x)
View(our_data)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + speed|hill_type + (hill_type|codex.factor) + (training|codex.factor), data = our_data)
View(ratings)
setwd("~/GitHub/Ski_jumping_data_center")
competitions = read.csv('all_comps.csv',sep=',',dec='.',stringsAsFactors = TRUE)
results = read.csv('all_results.csv',sep=',',dec='.',stringsAsFactors = TRUE)
ratings = read.csv('all_ratings.csv',sep=',',dec='.',stringsAsFactors = TRUE)
our_data = merge(results,ratings, by=c('codex','id','round')) %>% merge(competitions, by=c('id'))
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training,cumm_rating) %>% drop_na
our_data['hill_type'] = cut(our_data$hill_size_x, breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
our_data['norm_dist'] = our_data$dist/our_data$hill_size_x
our_data['codex.factor'] = factor(x=our_data$codex.x)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + speed|hill_type + (hill_type|codex.factor) + (training|codex.factor), data = our_data)
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + speed|hill_type + (1|hill_size.x/codex.factor), data = our_data)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + speed|hill_type + (1|hill_size_x/codex.factor), data = our_data)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + speed|hill_type + (1|hill_type/codex.factor), data = our_data)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + (1|hill_type:codex.factor), data = our_data)
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + hill_type + (1|hill_type:codex.factor), data = our_data)
summary(mixed.lmer)
View(mixed.lmer)
mixed.lmer$u
plot(mixed.lmer)
print(mixed.lmer)
our_data = merge(results,ratings, by=c('codex','id','round')) %>% merge(competitions, by=c('id'))
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training,cumm_rating) %>% drop_na $>$ filter(dist>0)
our_data = our_data %>% select(codex.x,hill_size_x,dist,wind,speed,training,cumm_rating) %>% drop_na %>% filter(dist>0 & speed > 0)
our_data['hill_type'] = cut(our_data$hill_size_x, breaks = c(0,85,115,160,300), labels=c('small', 'normal', 'large','flying hill'))
our_data['norm_dist'] = our_data$dist/our_data$hill_size_x
our_data['codex.factor'] = factor(x=our_data$codex.x)
mixed.lmer <- lmer(norm_dist ~ wind + cumm_rating + hill_type + (1|hill_type:codex.factor), data = our_data)
summary(mixed.lmer)
coef(mixed_lmer)
coef(mixed.lmer)
wsp = coef(mixed.lmer)
wsp = coef(mixed.lmer)[[1]]
View(wsp)
names = read.csv('all_names.csv',sep=',',dec='.',stringsAsFactors = TRUE)
View(names)
mixed.lmer <- lmer(norm_dist ~ wind + hill_type + speed|hill_type + (1|codex.factor) + (1|hill_type:codex.factor), data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ wind + hill_type + speed + speed:hill_type + (1|codex.factor) + (1|hill_type:codex.factor), data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
View(wsp)
View(names)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (1|hill_type:codex.factor) wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (1|hill_type:codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
View(wsp)
mixed.lmer <- lmer(norm_dist ~ 1 + (1|codex.factor) + (1|hill_type:codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
View(wsp)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (hill_type|codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ (1 + hill_type|codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (1|hill_type:codex_factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (1|hill_type:codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
View(wsp)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (1|hill_type:codex.factor) + (1|training:codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
our_data['norm_dist'] = our_data$dist/our_data$hill_size_x
our_data['codex.factor'] = factor(x=our_data$codex.x)
our_data['training.factor'] = factor(x=our_data$training)
mixed.lmer <- lmer(norm_dist ~ (1|codex.factor) + (1|hill_type:codex.factor) + (1|training.factor:codex.factor) + wind + hill_type + speed + speed:hill_type, data = our_data)
wsp = coef(mixed.lmer)[[1]]
summary(mixed.lmer)
View(our_data)
